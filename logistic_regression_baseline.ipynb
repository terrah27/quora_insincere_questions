{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2545a3ad7f22c0d72d465b639be421320a7d0896"
   },
   "source": [
    "# Quora Insincere Questions Logistic Regression Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "test = pd.read_csv('../test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaddf3f534ef2e9fe14142e844ce12426453961b"
   },
   "source": [
    "#### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "280ef1c0380632da7c0867e1887195e026e2afd3"
   },
   "outputs": [],
   "source": [
    "# taking a small sample (with downsampling of majority class) of the training data to correct class imbalance\n",
    "from sklearn.utils import resample\n",
    "\n",
    "sincere = train[train.target == 0]\n",
    "insincere = train[train.target == 1]\n",
    "\n",
    "train = pd.concat([resample(sincere,\n",
    "                     replace = False,\n",
    "                     n_samples = len(insincere)), insincere])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ee99bc21de267796eccacc8941a35d4e1667f6de"
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "c_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "d2dd1693f3eccef038cff273125e934b55af1003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [invent, modern, portfolio, theory]\n",
       "1    [place, sleep, amsterdam, airport, night, arrive]\n",
       "2                      [expansion, general, kth, term]\n",
       "3                        [accomodation, month, berlin]\n",
       "4    [buddhism, popular, religion, india, religion,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to clean and lemmatize text and remove stopwords\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_non_alphanum, remove_stopwords, strip_short\n",
    "\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), #lowercase\n",
    "                  strip_tags, # remove html tags\n",
    "                  strip_punctuation, # replace punctuation with space\n",
    "                  strip_multiple_whitespaces,# remove repeating whitespaces\n",
    "                  strip_non_alphanum, # remove non-alphanumeric characters\n",
    "                  strip_numeric, # remove numbers\n",
    "                  remove_stopwords,# remove stopwords\n",
    "                  strip_short # remove words less than minsize=3 characters long\n",
    "                 ]\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def gensim_preprocess(docs, logging=True):\n",
    "    docs = [expandContractions(doc) for doc in docs]\n",
    "    docs = [preprocess_string(text, CUSTOM_FILTERS) for text in docs]\n",
    "    texts_out = []\n",
    "    for doc in docs:\n",
    "    # https://spacy.io/usage/processing-pipelines\n",
    "        doc = nlp((\" \".join(doc)),  # doc = text to tokenize => creates doc\n",
    "                  # disable parts of the language processing pipeline we don't need here to speed up processing\n",
    "                  disable=['ner', # named entity recognition\n",
    "                           'tagger', # part-of-speech tagger\n",
    "                           'textcat', # document label categorizer\n",
    "                          ])\n",
    "        texts_out.append([tok.lemma_ for tok in doc if tok.lemma_ != '-PRON-'])\n",
    "    return pd.Series(texts_out)\n",
    "\n",
    "gensim_preprocess(train.question_text.iloc[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "cbef750800237534670c371bcf4103d18e06529d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 21s, sys: 26min 32s, total: 58min 53s\n",
      "Wall time: 12min 50s\n"
     ]
    }
   ],
   "source": [
    "# apply text-preprocessing function to training set\n",
    "%time train_corpus = gensim_preprocess(train.question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1ce2d567ac6c5acd054db57b1668afed85238c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'learn', 'develope', 'app', 'linux']\n"
     ]
    }
   ],
   "source": [
    "# create ngrams\n",
    "ngram_phraser = models.Phrases(train_corpus, threshold=1)\n",
    "ngram = models.phrases.Phraser(ngram_phraser)\n",
    "#print example\n",
    "print(ngram[train_corpus[0]])\n",
    "\n",
    "# apply model to corpus\n",
    "texts = [ngram[token] for token in train_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "583d3666f78e0c4a4c881020462a77fdb75e2a64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243613</th>\n",
       "      <td>2fa4ba03c124bf94fdd8</td>\n",
       "      <td>What is the best to learn developing apps on L...</td>\n",
       "      <td>0</td>\n",
       "      <td>well learn develope app linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383126</th>\n",
       "      <td>4b16b43ccee0d0375d73</td>\n",
       "      <td>What is the indirect competitors of Starbucks?</td>\n",
       "      <td>0</td>\n",
       "      <td>indirect competitor starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995356</th>\n",
       "      <td>c30ee49476e64839b1c9</td>\n",
       "      <td>How are high level nuclear waste being dispose...</td>\n",
       "      <td>0</td>\n",
       "      <td>high_level nuclear_waste dispose worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737244</th>\n",
       "      <td>9063754fa48fa7c9eed4</td>\n",
       "      <td>What is so great about Google's Associate Prod...</td>\n",
       "      <td>0</td>\n",
       "      <td>great google associate product_manager http_ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44857</th>\n",
       "      <td>08c89ffca45ed16018f6</td>\n",
       "      <td>Which IIT to choose for mtech CSE, IIT Kanpur,...</td>\n",
       "      <td>0</td>\n",
       "      <td>iit choose mtech cse_iit kanpur iit kgp iit_ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "243613  2fa4ba03c124bf94fdd8   \n",
       "383126  4b16b43ccee0d0375d73   \n",
       "995356  c30ee49476e64839b1c9   \n",
       "737244  9063754fa48fa7c9eed4   \n",
       "44857   08c89ffca45ed16018f6   \n",
       "\n",
       "                                            question_text  target  \\\n",
       "243613  What is the best to learn developing apps on L...       0   \n",
       "383126     What is the indirect competitors of Starbucks?       0   \n",
       "995356  How are high level nuclear waste being dispose...       0   \n",
       "737244  What is so great about Google's Associate Prod...       0   \n",
       "44857   Which IIT to choose for mtech CSE, IIT Kanpur,...       0   \n",
       "\n",
       "                                                   ngrams  \n",
       "243613                      well learn develope app linux  \n",
       "383126                      indirect competitor starbucks  \n",
       "995356         high_level nuclear_waste dispose worldwide  \n",
       "737244  great google associate product_manager http_ww...  \n",
       "44857   iit choose mtech cse_iit kanpur iit kgp iit_ma...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing ngrams for modeling\n",
    "texts = [' '.join(text) for text in texts]\n",
    "train['ngrams'] = texts\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d1463ba8f2e18e348ab6102dd2cf91c5cf16c815"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# represent features as BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train.ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7bc9ba1b315c6b1b212483f6a1d34ffe2f406d7a"
   },
   "source": [
    "### Logistic Regression Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e0df2aecb50730e61c034849bdcf2f7e4859e379"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score:  0.8692921668110383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.ngrams, train.target, test_size=0.2)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(vectorizer.transform(X_train), y_train)\n",
    "\n",
    "print('Logistic Regression Score: ', lr.score(vectorizer.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "48b67400149772936e26fcfc948c31e34f3ca7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87     16288\n",
      "           1       0.89      0.85      0.87     16036\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     32324\n",
      "   macro avg       0.87      0.87      0.87     32324\n",
      "weighted avg       0.87      0.87      0.87     32324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_ = lr.predict(vectorizer.transform(X_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "2178c186bf7d20e290985e7a5ee38101506b6926"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14528</td>\n",
       "      <td>1760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2465</td>\n",
       "      <td>13571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  14528   1760\n",
       "1   2465  13571"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "357e04b0d108c0ad84ef4dd8087ee67865bb567a"
   },
   "outputs": [],
   "source": [
    "# # preprocessing/lemmatizing/stemming test data\n",
    "# %time test_corpus = gensim_preprocess(test.question_text)\n",
    "# test_texts = [ngram[token] for token in test_corpus]\n",
    "\n",
    "# test_texts = [' '.join(text) for text in test_texts]\n",
    "# test['ngrams'] = test_texts\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d68e864af34a1b23d618021a1b42f023d08e6b6b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29387b5be1a7b43c871c68c1cb1c9889ed3ed302"
   },
   "source": [
    "Our logistic regression baseline model F1 score is 0.483!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 76 ms, total: 1.32 s\n",
      "Wall time: 1.32 s\n",
      "Naive Bayes Score:  0.8646825887885162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "%time bnb.fit(vectorizer.transform(X_train), y_train)\n",
    "\n",
    "print('Naive Bayes Score: ', bnb.score(vectorizer.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 321 ms, sys: 7.33 ms, total: 328 ms\n",
      "Wall time: 326 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86     16288\n",
      "           1       0.85      0.88      0.87     16036\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     32324\n",
      "   macro avg       0.87      0.86      0.86     32324\n",
      "weighted avg       0.87      0.86      0.86     32324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time bnb_y_ = bnb.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(classification_report(y_test, bnb_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13783</td>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869</td>\n",
       "      <td>14167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  13783   2505\n",
       "1   1869  14167"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, bnb_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
